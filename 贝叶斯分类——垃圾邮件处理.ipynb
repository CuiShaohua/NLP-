{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip_gram模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N_gram\n",
    "由词汇w1:wT组成的句子，其联合概率模型为：  \n",
    "$$ P(w_1:w_T) = P(w_1)*\\prod_{i=2}^n ~(P(w_i|w_1, w_{i-1}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照马尔科夫链假设，考虑1_gram，2_gram和3_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "0& \\text{x=0}\\\\\n",
    "1& \\text{x!=0}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_1:) = P(w_1)*P(w_2 |w_1)*P(w_3|w_2)*...*P(w_n|w_{n-1}) $$\n",
    "$$ P(w_1:) = P(w_1)*P(w_2 |w_1)*P(w_3|w_2,w_1) *...P(w_n|w_{n-1},w_{n-2})$$\n",
    "$$ P(w_1:) = P(w_1)*P(w_2 |w_1)*P(w_3|w_2,w_1)* ...P(w_n|w_{n-1},w_{n-2},w_{n-3})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在基于大量语料情况下，可以根据大数定理（试验次数很大，结果接近于概率分布）来计算上述的概率：\n",
    "$$ P(w_2|w_1) = \\frac{Counter(w_1,w_2)}{Counter(w_1)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上述可知，只需要统计<b>```语料```</b>中出现$w_1$词的次数和$w_1和w_2$一起出现的次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 截止目前为止，并没有跟贝叶斯公式有什么联系，接下来我们看怎么联系上的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q1：如何根据上述1_gram模型，判断某个邮件（句子）是不是垃圾邮件？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e.g.  \n",
    "现在假设我们有垃圾邮件和正常邮件各1万封作为训练集。需要判断以下这个邮件是否属于垃圾邮件：  \n",
    "```“我司可办理正规发票（保真）17%增值税发票点数优惠！”```  \n",
    "也就是判断概率$ P(“垃圾邮件”∣“我司可办理正规发票（保真）17\\%增值税发票点数优惠！”)>0.5$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 基于大数定理，根据频率概念，我们可能获得以下解法：\\\n",
    "\\\n",
    "$$ P(“垃圾邮件”∣“我司可办理正规发票（保真）17\\%增值税发票点数优惠！”)=\\ \\frac{垃圾邮件中出现这句话的次数}{垃圾邮件中出现这句话的次数+普通邮件中出现这句话的次数}\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">   但是往往想象很美好，现实却很残酷。由于我们中文的强大，要表达这句话的意思的句子有很多种，而且训练集又是有限的，所以要想覆盖所有句子可能性的训练集根本不存在。那么我们又应该如何处理这个问题呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 句子是多样性的，但是表达这句话意思的词语就那么些。  \n",
    "因此，我们进行分词之后，将词语集合代表这个句子。\\\n",
    "依据这些特征词我们之前的贝叶斯公式就变成了：\n",
    "\n",
    "$$ P\\big(“垃圾邮件”|(...)\\big)=\\frac{P\\big((...)|“垃圾邮件”\\big)P(“垃圾邮件”)}{P\\big((...)\\big)}\n",
    "$$\n",
    "$$ P\\big(“普通邮件”|(...)\\big)=\\frac{P\\big((...)|“普通邮件”\\big)P(“普通邮件”)}{P\\big((...)\\big)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 从这个地方开始，属性条件独立假设，即每个词的出现都是独立的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\"垃圾邮件\"|(...))=\\frac{P(“垃圾邮件”)}{P\\big((...)\\big)} ~~\\prod_{i=1}^dP\\big(x_i|“垃圾邮件”\\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
